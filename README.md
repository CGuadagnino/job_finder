# SWE Finder

A full-stack job aggregation platform for software engineers, featuring a Rust backend API and React frontend. The application aggregates job listings from the Adzuna API and provides a fast, searchable interface for finding remote and California-based tech positions.

ðŸ”— **Live Demo**: [swefinder.vercel.app](https://swefinder.vercel.app)

## Features

- **Real-time Job Search** â€” Instant filtering across job titles, companies, locations, and descriptions
- **Smart Tag Extraction** â€” Automatically detects and displays relevant tech skills (React, Python, AWS, etc.)
- **Infinite Scroll** â€” Smooth lazy-loading of job results for optimal performance
- **Job Detail Modal** â€” View full job descriptions with direct apply links
- **Bulk Job Ingestion** â€” Automated pipeline to fetch jobs from Adzuna API and ingest directly to Supabase
- **Duplicate Prevention** â€” URL-based deduplication ensures no duplicate listings
- **Cloud Database Integration** â€” Direct ingestion to Supabase PostgreSQL for production-ready deployment

## Tech Stack

### Frontend
| Technology | Purpose |
|------------|---------|
| React 19 | UI framework |
| TypeScript | Type safety |
| Vite | Build tool & dev server |
| TailwindCSS | Styling |
| TanStack Query | Server state management |
| Supabase JS | Database client |

### Backend
| Technology | Purpose |
|------------|---------|
| Rust | Backend language |
| Axum | Web framework |
| SQLx | Database driver (PostgreSQL) |
| Tokio | Async runtime |
| Reqwest | HTTP client |

### Infrastructure
| Service | Purpose |
|---------|---------|
| **Vercel** | Frontend hosting |
| **Supabase** | PostgreSQL database (production & development) |
| Adzuna API | Job data source |

## Project Structure

```
job_finder/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.rs           # Server entry point & routing
â”‚   â”‚   â”œâ”€â”€ db.rs             # Database initialization & queries
â”‚   â”‚   â”œâ”€â”€ models.rs         # Data structures & types
â”‚   â”‚   â”œâ”€â”€ handlers/
â”‚   â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”‚   â”œâ”€â”€ health.rs     # Health check endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ jobs.rs       # CRUD operations for jobs
â”‚   â”‚   â”‚   â””â”€â”€ ingest.rs     # Adzuna ingestion handler
â”‚   â”‚   â””â”€â”€ ingest/
â”‚   â”‚       â”œâ”€â”€ mod.rs
â”‚   â”‚       â””â”€â”€ adzuna.rs     # Adzuna API client
â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â”œâ”€â”€ batch_ingest.sh       # Batch job ingestion script (macOS/Linux)
â”‚   â””â”€â”€ weekly_ingest.ps1     # Batch job ingestion script (Windows)
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ main.tsx          # React entry point
    â”‚   â”œâ”€â”€ App.tsx           # Main application component
    â”‚   â”œâ”€â”€ types.ts          # TypeScript interfaces
    â”‚   â”œâ”€â”€ lib/
    â”‚   â”‚   â””â”€â”€ supabase.ts   # Supabase client config
    â”‚   â””â”€â”€ components/
    â”‚       â”œâ”€â”€ SearchBar.tsx # Search input component
    â”‚       â”œâ”€â”€ JobList.tsx   # Virtualized job list
    â”‚       â”œâ”€â”€ JobCard.tsx   # Individual job card
    â”‚       â””â”€â”€ JobModal.tsx  # Job detail modal
    â”œâ”€â”€ package.json
    â”œâ”€â”€ vite.config.ts
    â””â”€â”€ tailwind.config.js
```

## Getting Started

### Prerequisites

- **Rust** (latest stable) â€” [Install](https://rustup.rs/)
- **Node.js** v18+ â€” [Install](https://nodejs.org/)
- **Adzuna API credentials** â€” [Sign up](https://developer.adzuna.com/)
- **Supabase account** â€” [Sign up](https://supabase.com/)

### Backend Setup

1. Navigate to the backend directory:
   ```bash
   cd backend
   ```

2. Create a `.env` file with your Adzuna and Supabase credentials:
   ```env
   ADZUNA_APP_ID=your_app_id
   ADZUNA_APP_KEY=your_app_key
   DATABASE_URL=postgresql://postgres.[PROJECT-REF]:[YOUR-PASSWORD]@aws-0-[REGION].pooler.supabase.com:5432/postgres
   ```
   
   **Get your DATABASE_URL:**
   - Go to Supabase Dashboard â†’ Settings â†’ Database
   - Under "Connection string", select **Session pooler**
   - Copy the URI and replace `[YOUR-PASSWORD]` with your database password

3. Build and run the server:
   ```bash
   cargo run
   ```
   The API will start at `http://127.0.0.1:3000`

### Frontend Setup

1. Navigate to the frontend directory:
   ```bash
   cd frontend
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Create a `.env` file with your Supabase credentials:
   ```env
   VITE_SUPABASE_URL=your_supabase_project_url
   VITE_SUPABASE_ANON_KEY=your_supabase_anon_key
   ```

4. Start the development server:
   ```bash
   npm run dev
   ```
   The app will open at `http://localhost:5173`

## API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | Health check |
| `GET` | `/jobs` | List all jobs (optional `?keyword=` filter) |
| `POST` | `/jobs` | Create a single job |
| `POST` | `/jobs/bulk` | Bulk create jobs (max 500) |
| `GET` | `/ingest/adzuna` | Fetch jobs from Adzuna API and insert to Supabase |

### Ingest Query Parameters

| Parameter | Type | Description |
|-----------|------|-------------|
| `keyword` | string | Search term (required) |
| `location` | string | Location filter |
| `remote_only` | boolean | Filter for remote positions |
| `max_days_old` | number | Maximum age of listings |

**Example:**
```bash
curl "http://127.0.0.1:3000/ingest/adzuna?keyword=react+developer&location=california&remote_only=true&max_days_old=30"
```

## Database Schema

### Jobs Table

```sql
CREATE TABLE jobs (
    id SERIAL PRIMARY KEY,
    title TEXT NOT NULL,
    company TEXT NOT NULL,
    location TEXT NOT NULL,
    url TEXT NOT NULL UNIQUE,
    description TEXT NOT NULL,
    created_at TIMESTAMPTZ DEFAULT NOW()
);
```

### Supabase Setup

1. Create a new Supabase project
2. Run the schema above in the SQL editor
3. Copy your project URL and anon key to the frontend `.env`
4. Copy your database connection string (Session pooler) to the backend `.env`
5. Enable Row Level Security (RLS) and add a read policy for anonymous users:
   ```sql
   CREATE POLICY "Allow anonymous read access" ON jobs
       FOR SELECT USING (true);
   ```

## Job Ingestion

Automated ingestion scripts are provided for both macOS/Linux (`batch_ingest.sh`) and Windows (`weekly_ingest.ps1`). These scripts perform bulk job ingestion across 50+ search queries covering:

- **Remote positions**: Software engineers, frontend/backend developers, DevOps, ML engineers, mobile developers
- **California positions**: Same role categories for local opportunities

Each query fetches up to 500 jobs (10 pages Ã— 50 results). The backend automatically:
- Inserts jobs directly to Supabase PostgreSQL
- Handles duplicates via `ON CONFLICT (url) DO NOTHING`
- Returns counts of inserted and skipped jobs

### Running the Ingestion Script

**macOS/Linux:**
```bash
# Ensure backend is running first
cd backend
cargo run

# In another terminal, run the ingestion script
chmod +x batch_ingest.sh
./batch_ingest.sh
```

**Windows (PowerShell):**
```powershell
# Ensure backend is running first
cd backend
cargo run

# In another terminal, run the ingestion script
./weekly_ingest.ps1
```

The ingestion process typically takes 10-15 minutes and can add thousands of jobs to your database.

## Environment Variables

### Backend (.env)

| Variable | Description |
|----------|-------------|
| `ADZUNA_APP_ID` | Adzuna API application ID |
| `ADZUNA_APP_KEY` | Adzuna API application key |
| `DATABASE_URL` | Supabase PostgreSQL connection string (Session pooler) |

### Frontend (.env)

| Variable | Description |
|----------|-------------|
| `VITE_SUPABASE_URL` | Supabase project URL |
| `VITE_SUPABASE_ANON_KEY` | Supabase anonymous/public key |

## Deployment

### Frontend (Vercel)

1. Connect your GitHub repository to Vercel
2. Set the root directory to `frontend`
3. Add environment variables in project settings:
   - `VITE_SUPABASE_URL`
   - `VITE_SUPABASE_ANON_KEY`
4. Deploy automatically on push to `main`

### Backend (Optional)

The backend can be deployed to services like:
- **Fly.io** â€” Rust-friendly with PostgreSQL support
- **Railway** â€” Simple deployment with automatic HTTPS
- **Render** â€” Free tier available

Or run locally and use the ingestion scripts to populate Supabase directly.

### Database (Supabase)

The production database is hosted on Supabase and can be populated by:
1. Running the backend locally with `DATABASE_URL` pointing to your Supabase instance
2. Executing the ingestion scripts (`batch_ingest.sh` or `weekly_ingest.ps1`)
3. Jobs are inserted directly to Supabase in real-time

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is open source and available under the [MIT License](LICENSE).

---

Built with â˜• and Rust ðŸ¦€
